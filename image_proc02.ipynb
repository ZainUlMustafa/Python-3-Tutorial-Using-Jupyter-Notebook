{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing\n",
    "This is a follow up and advancement of the first tutorial on image processing. \n",
    "\n",
    "#### Disclaimer:\n",
    "If by following this second tutorial you feel like:\n",
    "<img src=\"data/wtf.gif\" width=\"500\">\n",
    "Then go **read the first tutorial** again carefully.\n",
    "\n",
    "But if you have understood all that was described in the first, **congrats on your first research!**\n",
    "<img src=\"data/research.gif\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Detection\n",
    "Boundaries of any object is called an edge. In image processing you can extract the edges of object by very ease. It is basically a high pass filter that completely removes anything that is not an edge. \n",
    "\n",
    "<img src=\"data/canny.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('samples/D (198).jpg')\n",
    "im = cv2.resize(img, (500,500))\n",
    "gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "edges = cv2.Canny(gray, 550, 150)\n",
    "\n",
    "cv2.imshow('im', im)\n",
    "cv2.imshow('gray', gray)\n",
    "cv2.imshow('edges', edges)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try it out with a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    _, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray, 50, 100)\n",
    "    \n",
    "    cv2.imshow('frame', frame)\n",
    "    cv2.imshow('edges', edges)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Tracking\n",
    "As we have covered all the basics of image processing which includes masking, finding edges, knowing the shape of images and frames of video; we can now proceed towards **making an object tracker from scratch!**\n",
    "\n",
    "This will include the concept of:\n",
    "- threshold\n",
    "- contours \n",
    "- image moments \n",
    "- finding the area of images\n",
    "- finding the coordinates of contours\n",
    "- drawing the boundary around the object using those coordinates\n",
    "\n",
    "#### Contours:\n",
    "Any closed area is a contour. As seen from the edge detector concept, every closed area you see there is a contour.\n",
    "#### Image Moments:\n",
    "The weighted average of all the pixel intensities in a image is called moment. We can find out the center of the weighted average hence, can calculate the centroid of an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "min_area = 100*100\n",
    "\n",
    "while(cap.isOpened):\n",
    "    _,frame = cap.read()\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    upper = np.array([54,134,93])\n",
    "    lower = np.array([255,255,255])\n",
    "    \n",
    "    mask = cv2.inRange(hsv, upper, lower)\n",
    "    res = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "    \n",
    "    # detection of contours\n",
    "    res_gray = cv2.cvtColor(res, cv2.COLOR_BGR2GRAY)\n",
    "    _, threshold = cv2.threshold(res_gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    _, contours, _ = cv2.findContours(threshold, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area>min_area:\n",
    "            # calculating the centroid\n",
    "            moment = cv2.moments(contour)\n",
    "            cx = int(moment['m10']/moment['m00'])\n",
    "            cy = int(moment['m01']/moment['m00'])\n",
    "            \n",
    "            # make a rectangle bounding the contour\n",
    "            [x, y, w, h] = cv2.boundingRect(contour)\n",
    "            \n",
    "            # draw a rectangle surrounding the contour image\n",
    "            cv2.rectangle(frame, (x, y), (w+x, h+y), (0,255,0), 2)\n",
    "            \n",
    "            # put the centroid text\n",
    "            cv2.putText(frame, str(cx)+','+str(cy), (cx,cy), 2, 1, (255,0,0), 1, 0)\n",
    "        #endif\n",
    "    #endfor\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "    #endif\n",
    "#endwhile\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Workshops\n",
    "We at ***NUST Air Works*** have a strong belief in sharing information and keep learning, adopting, and adapting to newer and advanced concepts. In the future we are working on a new project for you which is solely on further image processing and machine learning. We are glad that you attended this workshop and we hope that you have learnt something from our team.\n",
    "\n",
    "### The End\n",
    "<img src=\"data/theend.gif\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
