{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing\n",
    "It is a technique used for the analysis of an image in order to manipulate it and extract information from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/im1.png\" width=\"600\">\n",
    "<img src=\"data/im2.PNG\" width=\"600\">\n",
    "<img src=\"data/im3.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the purpose of image processing?\n",
    "- <b>Visualization</b> - Observe the objects that are not visible.\n",
    "- <b>Image Sharpening and Restoration</b> - To create a better image.\n",
    "- <b>Image Retrieval</b> - Seek for the image of interest.\n",
    "- <b>Measurement of Pattern</b> - Measures various objects in an image.\n",
    "- <b>Image Recognition</b> - Distinguish the objects in an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python can do this all!\n",
    "Is there anything that Python can't do. You have to be kidding me!\n",
    "\n",
    "**OpenCV is a Open-source computer vision** library available for multiple platforms including C++.\n",
    "But first let's take a sneak peek at code of C++ I used for simplistic image processing task.\n",
    "<img src=\"data/c++.PNG\" width=\"2000\">\n",
    "\n",
    "**Too many words, the hell with this shit!**\n",
    "It literally took me two months to actually learn to code this, with clear concepts of course. Plus it's tedious to set up the libraries and do the required configurations before you can write the actual code. If you do really want to check that out though, I have maintained a journal containing core code concepts for C++ to use with OpenCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving forward with Python\n",
    "Yes, people may claim why Python when much faster language exists that can process images way faster. I ask them, even if it is faster is it faster to debug them or write the code and not get stuck with the grammar of it?\n",
    "\n",
    "**Disclaimer:** If you are hating C++ right at this instant, Python is built on C++.\n",
    "***So C++ is going nowhere!***\n",
    "<img src=\"data/haters.gif\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing OpenCV on Python\n",
    "OpenCV have a pre-compiled solution **(pip install opencv-python==3.4.7.28)** or you can compile it from source (check opencv github repo).  \n",
    "\n",
    "<img src=\"data/tenor.gif\" width=\"500\">\n",
    "\n",
    "Still worried, this site: https://www.lfd.uci.edu/~gohlke/pythonlibs/#opencv would get you covered. Open-source community is heavenly and it would go straight to ***Jana'ah***. This community has compiled the package of nearly every popular library and API for **Windows** and provided the complete solution. The download will be a **.whl** file. Choose appropriate version according to your Python version and your processor (32-bit or 64-bit).\n",
    "\n",
    "Open CMD and go to directory where the downloaded file is present and install in this way:\n",
    "- pip install \"opencv_python‑3.4.3‑cp36‑cp36m‑win_amd64.whl\"\n",
    "\n",
    "### And now let's code\n",
    "***With few functions always in mind:***\n",
    "- imread( ***directory*** )\n",
    "- imshow( image )\n",
    "- cvtColor( image, ***conversion_from_and_to*** )\n",
    "- imwrite( ***directory***, image )\n",
    "- VideoCapture( ***address*** )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f597844fe80>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read the image\n",
    "im = cv2.imread('samples/1 (1).png')\n",
    "# Display the original image\n",
    "im = cv2.resize(im, (10,10))\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing the original image\n",
    "original -> BGR to gray -> resizing -> display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5978423400>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's change the RGB image (or BGR as said in OpenCV) to Grayscale\n",
    "#im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "im = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n",
    "# Now if you want to resize the image to 10x10 \n",
    "im = cv2.resize(im, (10,10))\n",
    "# Display the processed image\n",
    "#cv2.imshow('gray',im)\n",
    "#cv2.waitKey(0)\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the normalized pixel values\n",
    "Normalization can be done by dividing the pixel values by the higest number possible which in the case of images in 255.\n",
    "**Notice how matrix values printed below is exact representation of the image**\n",
    "- 0 -> Black\n",
    "- 1 -> White"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 0. 0. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 0. 0. 0. 0. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(im/255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the image with the pixel values\n",
    "<img src=\"data/resC.PNG\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A video is just a collection of images\n",
    "When a set of 60 images are displayed in a second, a video is born. A 10 second video basically contains 60x10 = 600 images.\n",
    "In OpenCV you can process the video in a very similar fashion like that of still images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the video or open the webcam.\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Read the first frame, then the second, then the third, and so on.\n",
    "# You will require a loop that can read new frame in every iteration and display it\n",
    "while(cap.isOpened()):\n",
    "    # Read the frame\n",
    "    _, frame = cap.read()\n",
    "    cv2.imshow('original',frame)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imshow('gray', gray)\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    cv2.imshow('hsv', hsv)\n",
    "    \n",
    "    # In order to end the process or video forcefully, press 'q'\n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the memory. If you don't do this, it will eat up your memory and program will crash ultimately        \n",
    "cap.release()\n",
    "# Close all the opened windows because either the video has been finished or you forcefully ended the video\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Notice the while block:*** The process taking place in the body is exactly the same as that of the still images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept Alert!\n",
    "There is a **don't care variable** in the code above represented by an underscore. Sometimes you don't care about the variable name because they are not used anywhere in the code so you just let Python take care of it and name it anything it want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "_ = 24\n",
    "print(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing you might have seen is this:\n",
    "- a, b = somefunc()\n",
    "\n",
    "This simply means that if a function returns two values, you can say that first value goes into 'a' and the second goes into 'b'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "def twonum():\n",
    "    return 2,3\n",
    "\n",
    "_, b = twonum()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flip the frames\n",
    "Sometimes during the training of the AI system, the data available is not enough. One way to increase the data is to make small changes to the existing data. This is known as **Data Augmentation**. In case of the images, you can flip them and add these generated images to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:\n",
    "        frame = cv2.flip(frame, 0)\n",
    "        # Flip the frame\n",
    "        cv2.imshow('frame',frame)\n",
    "    \n",
    "        # In order to end the process or video forcefully, press 'q'\n",
    "        if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing on the images\n",
    "Very often in **Object Localization** the computer draws a boundary around the image showing you where the object is. \n",
    "\n",
    "**For Example:** In the image below, AI system has not only accurately predicted the character but also shows where the character is in the image.\n",
    "<img src=\"data/chardata.jpg\" width=\"1000\">\n",
    "\n",
    "### Further examples include\n",
    "Complex image segmentation and localization, many of which is done by a simple function call in Python.\n",
    "<img src=\"data/boundary.png\" width=\"1000\">\n",
    "<img src=\"data/boundary2.PNG\" width=\"1000\">\n",
    "\n",
    "### With that motivation\n",
    "Let's learn how the computer draws on the image, shall we? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A 2D array of zeros as we saw means the image is black\n",
    "# The following code is to create a black image of size 100x100\n",
    "img = np.zeros((500,500,3), np.uint8)\n",
    "\n",
    "# cv2.line(image, (x_init, y_init), (h, w), (b, g, r), line_width)\n",
    "img = cv2.line(img, (0,80), (500,80), (255,0,0), 2)\n",
    "img = cv2.line(img, (0,60), (260,500), (0,255,0), 2)\n",
    "img = cv2.line(img, (240,500), (500,60), (0,0,255), 2)\n",
    "\n",
    "# cv2.rectangle(img, (x_2, y_1), (x_1, y_2), (b, g, r), line_width)\n",
    "img = cv2.rectangle(img, (350,200), (150,300), (255,255,255), 2)\n",
    "\n",
    "# cv2.circle(img, (x_cen, y_cen), radius, (b, g, r), fill)\n",
    "img = cv2.circle(img,(250,250), 20, (255,0,255), -1)\n",
    "\n",
    "# cv2.putText(img, text, (x, y), font, size, (b, g, r), boldness, 0)\n",
    "cv2.putText(img,'Hello World~', (150,150), 2, 1, (255,255,255), 1, 0)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "img = cv2.resize(img, (1000,1000))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try drawing these\n",
    "<img src=\"data/drawthis.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masking\n",
    "In order to extract a specific color from the image, a concept known as masking is used. This concept can be understood intuitively. Mask is simply the array of pixels which you want to consider only and all the other pixels are turned to zero. \n",
    "\n",
    "<img src=\"data/masking.PNG\" width=\"1000\">\n",
    "\n",
    "**Mask is a Binary Image!**\n",
    "\n",
    "But now you want to retain the color of the object as well. Therefore, we can apply AND operation on the mask and the original image. The pixels in the mask which were zero will turn the result of AND operation to become zero. Similarly the pixels in the mask which were ones will turn the result of AND operation to be unaffected.\n",
    "\n",
    "It is better explained by the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('samples/C (60).jpg')\n",
    "im = cv2.resize(img, (500,500))\n",
    "cv2.imshow('image', im)\n",
    "\n",
    "# Always convert the image to HSV for masking\n",
    "hsv = cv2.cvtColor(im, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Define the color you want for mask\n",
    "lower_red = np.array([100,130,150])\n",
    "upper_red = np.array([255,255,255])\n",
    "\n",
    "# Apply the mask\n",
    "mask = cv2.inRange(hsv, lower_red, upper_red)\n",
    "cv2.imshow('mask', mask)\n",
    "\n",
    "# Do the AND operation on mask and original image\n",
    "res = cv2.bitwise_and(im, im, mask=mask)\n",
    "cv2.imshow('res', res)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But how to find out the masking values?\n",
    "Trust me, you have to play with it and test it repeatedly on images containing similar color until you find that sweet spot.\n",
    "\n",
    "### Wasn't anything not impossible with Python?\n",
    "So can we not resolve this trial and error thing to find the sweet spot and make an algorithm that makes it easy to do so. **Let's find out!**\n",
    "### Trackbars for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hsv ->  0 0 0\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('samples/1 (3).jpg')\n",
    "im = cv2.resize(img, (500,500))\n",
    "hsv = cv2.cvtColor(im, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# initialize by making a blank result image\n",
    "res = np.zeros((500,500,3), np.uint8)\n",
    "\n",
    "# creating a window on which image will be displayed\n",
    "cv2.imshow('image', im)\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "#initializing the values to be set using trackbars to be zero\n",
    "l_h,l_s,l_v = 0,0,0\n",
    "higher = 255\n",
    "\n",
    "# creating trackbars\n",
    "cv2.createTrackbar('h', 'image', l_h, higher, nothing)\n",
    "cv2.createTrackbar('s', 'image', l_s, higher, nothing)\n",
    "cv2.createTrackbar('v', 'image', l_v, higher, nothing)\n",
    "\n",
    "# with every new value from trackbar, image is needed to be refreshed and redisplayed\n",
    "while(True):\n",
    "    cv2.imshow('res', res)\n",
    "        \n",
    "    # get the trackbar positions and set them to l_h, l_s, l_v respectively\n",
    "    l_h = cv2.getTrackbarPos('h', 'image')\n",
    "    l_s = cv2.getTrackbarPos('s', 'image')\n",
    "    l_v = cv2.getTrackbarPos('v', 'image')\n",
    "    \n",
    "    lower_red = np.array([l_h,l_s,l_v])\n",
    "    upper_red = np.array([255,255,255])\n",
    "    \n",
    "    mask = cv2.inRange(hsv, lower_red, upper_red)\n",
    "    res = cv2.bitwise_and(im, im, mask=mask)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        print(\"hsv -> \",l_h,l_s,l_v)\n",
    "        break\n",
    "\n",
    "# save the image\n",
    "cv2.imwrite('samples/samples.jpg', res)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can we make trackbars for video\n",
    "Sure we can, just a little more code and more copy paste from above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hsv ->  162 58 62\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "#initializing the values to be set using trackbars to be zero\n",
    "l_h,l_s,l_v = 0,0,0\n",
    "higher = 255\n",
    "\n",
    "# creating trackbars\n",
    "cv2.namedWindow('image')\n",
    "cv2.createTrackbar('h', 'image', l_h, higher, nothing)\n",
    "cv2.createTrackbar('s', 'image', l_s, higher, nothing)\n",
    "cv2.createTrackbar('v', 'image', l_v, higher, nothing)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    _,frame = cap.read()\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    l_h = cv2.getTrackbarPos('h', 'image')\n",
    "    l_s = cv2.getTrackbarPos('s', 'image')\n",
    "    l_v = cv2.getTrackbarPos('v', 'image')\n",
    "    \n",
    "    lower_red = np.array([l_h,l_s,l_v])\n",
    "    upper_red = np.array([255,255,255])\n",
    "    \n",
    "    mask = cv2.inRange(hsv, lower_red, upper_red)\n",
    "    res = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "    \n",
    "    cv2.imshow('image', frame)\n",
    "    cv2.imshow('res', res)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        print(\"hsv -> \",l_h,l_s,l_v)\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Shape\n",
    "OpenCV gives you a handy facility to know the dimensions of your image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img:  (2988, 5312, 3)\n",
      "im:  (500, 500, 3)\n",
      "hsv:  (480, 640, 3)\n",
      "mask:  (480, 640)\n",
      "res:  (480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"img: \", img.shape)\n",
    "print(\"im: \", im.shape)\n",
    "print(\"hsv: \", hsv.shape)\n",
    "print(\"mask: \", mask.shape)\n",
    "print(\"res: \", res.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done with basics!\n",
    "<img src=\"data/done.gif\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
